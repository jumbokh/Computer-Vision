{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumbokh/Computer-Vision/blob/main/notebooks/face_recognition_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## https://github.com/Jim-Chang/KodingWork/tree/master/deep_learning/face_recognition"
      ],
      "metadata": {
        "id": "-ROZ5zuX6BYM"
      },
      "id": "-ROZ5zuX6BYM"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python numpy face-recognition pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfTT5vUT6ELV",
        "outputId": "3b922ef6-e8e9-42e2-8fcb-85955d3a7688"
      },
      "id": "jfTT5vUT6ELV",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Collecting face-recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Collecting face-recognition-models>=0.3.0 (from face-recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face-recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face-recognition) (19.24.2)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=dba6aae785dd7e53d0aa87066c5c1c943c955de1c249bc4bf69378c43eba0c05\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0f011ea6-f551-4c2a-b946-2c3f7aaaae2a",
      "metadata": {
        "tags": [],
        "id": "0f011ea6-f551-4c2a-b946-2c3f7aaaae2a"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2bc7be74-8ee9-46c7-a97c-c1fb97050c79",
      "metadata": {
        "tags": [],
        "id": "2bc7be74-8ee9-46c7-a97c-c1fb97050c79"
      },
      "outputs": [],
      "source": [
        "known_face_list = [\n",
        "    {\n",
        "        'name': 'Hyun Bin',\n",
        "        'filename': '玄彬.jpeg',\n",
        "        'encode': None,\n",
        "    },\n",
        "    {\n",
        "        'name': 'Son Ye Jin',\n",
        "        'filename': '孫藝珍.jpeg',\n",
        "        'encode': None,\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7ea942f1-aa29-4781-badc-462c805fd9ca",
      "metadata": {
        "tags": [],
        "id": "7ea942f1-aa29-4781-badc-462c805fd9ca"
      },
      "outputs": [],
      "source": [
        "# load image data\n",
        "for data in known_face_list:\n",
        "    img = cv2.imread(data['filename'])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    data['encode'] = face_recognition.face_encodings(img)[0]\n",
        "\n",
        "known_face_encodes = [data['encode'] for data in known_face_list]\n",
        "tolerance = 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9854ac2e-83c2-4df3-9497-003f83cb8c4a",
      "metadata": {
        "tags": [],
        "id": "9854ac2e-83c2-4df3-9497-003f83cb8c4a"
      },
      "outputs": [],
      "source": [
        "test_fn_list = ['孫藝珍-t1.jpeg', '孫藝珍-t2.jpeg', '孫藝珍-t3.jpeg', '玄彬+孫藝珍.jpeg']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88e446d6-3622-421d-8d0e-b7ea2399d7b7",
      "metadata": {
        "tags": [],
        "id": "88e446d6-3622-421d-8d0e-b7ea2399d7b7"
      },
      "source": [
        "## 如何儲存 Face Encoding 加速載入？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "07f768c2-5ad3-4bc1-a398-01d96879b2a4",
      "metadata": {
        "id": "07f768c2-5ad3-4bc1-a398-01d96879b2a4"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2b1f51ec-1066-4da6-88c4-73828275ed7e",
      "metadata": {
        "id": "2b1f51ec-1066-4da6-88c4-73828275ed7e"
      },
      "outputs": [],
      "source": [
        "# save known_face_list to dat file\n",
        "with open('faces.dat', 'wb') as f:\n",
        "    pickle.dump(known_face_list, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "65baba2a-5314-4619-8664-d2ed35fd4a84",
      "metadata": {
        "id": "65baba2a-5314-4619-8664-d2ed35fd4a84"
      },
      "outputs": [],
      "source": [
        "# load known_face_list from dat file\n",
        "with open('faces.dat', 'rb') as f:\n",
        "    known_face_list = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "424fb564-8308-4609-ab64-bd9386c38d09",
      "metadata": {
        "id": "424fb564-8308-4609-ab64-bd9386c38d09"
      },
      "source": [
        "## 發現有時會誤判人臉？改用 CNN 模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9a981099-b9e3-4564-b697-2ad6bcfe99fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a981099-b9e3-4564-b697-2ad6bcfe99fc",
        "outputId": "45f996f0-5832-4c25-db89-b383677eebdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOG: 0.35 secs, CNN: 1.26 secs\n",
            "HOG: 0.3 secs, CNN: 0.05 secs\n",
            "HOG: 0.23 secs, CNN: 0.21 secs\n",
            "HOG: 0.51 secs, CNN: 0.41 secs\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "for fn in test_fn_list:\n",
        "    img = cv2.imread(fn)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    _t = time.time()\n",
        "\n",
        "    face_recognition.face_locations(img) # use HOG model to detect face locations\n",
        "\n",
        "    _t1 = time.time()\n",
        "\n",
        "    face_recognition.face_locations(img, model='cnn') # use CNN model to detect face locations\n",
        "\n",
        "    print(f'HOG: {round(_t1 - _t, 2)} secs, CNN: {round(time.time() - _t1, 2)} secs')\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "660301c0-b328-4e83-b576-782d082592cf",
      "metadata": {
        "id": "660301c0-b328-4e83-b576-782d082592cf"
      },
      "source": [
        "## 準確度不夠？增加特徵點數量"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb19fe78-e604-40d0-a48d-10ff036a50a7",
      "metadata": {
        "id": "fb19fe78-e604-40d0-a48d-10ff036a50a7"
      },
      "source": [
        "### 使用 68 個特徵點"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "902dce61-29ec-4b32-8e45-266734372dd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "902dce61-29ec-4b32-8e45-266734372dd7",
        "outputId": "959b3dac-9725-4aeb-e112-9937fc311895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "辨識檔案: lee-t1.jpg, 辨識結果: Lee, 特徵距離: [('Lee', 0.3777), ('Pan', 0.4614)], 相差: 0.0837\n",
            "辨識檔案: lee-t2.jpg, 辨識結果: Lee, 特徵距離: [('Lee', 0.3033), ('Pan', 0.5545)], 相差: 0.2512\n",
            "辨識檔案: pan-t1.jpg, 辨識結果: Pan, 特徵距離: [('Lee', 0.4679), ('Pan', 0.2946)], 相差: 0.1733\n",
            "辨識檔案: pan-t2.jpg, 辨識結果: Lee, 特徵距離: [('Lee', 0.3897), ('Pan', 0.4047)], 相差: 0.015\n"
          ]
        }
      ],
      "source": [
        "known_face_list = [\n",
        "    {\n",
        "        'name': 'Lee',\n",
        "        'filename': 'lee.jpg',\n",
        "        'encode': None,\n",
        "    },\n",
        "    {\n",
        "        'name': 'Pan',\n",
        "        'filename': 'pan.jpg',\n",
        "        'encode': None,\n",
        "    },\n",
        "]\n",
        "\n",
        "test_fn_list = ['lee-t1.jpg', 'lee-t2.jpg', 'pan-t1.jpg', 'pan-t2.jpg']\n",
        "\n",
        "# load image data by large model of face landmarks\n",
        "for data in known_face_list:\n",
        "    img = cv2.imread(data['filename'])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    data['encode'] = face_recognition.face_encodings(img, model='large')[0]  # use large model of face landmarks\n",
        "\n",
        "known_face_encodes = [data['encode'] for data in known_face_list]\n",
        "\n",
        "# face recognition\n",
        "for fn in test_fn_list:\n",
        "    img = cv2.imread(fn)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    cur_face_locs = face_recognition.face_locations(img)\n",
        "    cur_face_encodes = face_recognition.face_encodings(img, cur_face_locs, model='large')  # use large model of face landmarks\n",
        "\n",
        "    for cur_face_encode in cur_face_encodes:\n",
        "        face_distance_list = face_recognition.face_distance(known_face_encodes, cur_face_encode)\n",
        "\n",
        "        min_distance_index = np.argmin(face_distance_list)\n",
        "        if face_distance_list[min_distance_index] < tolerance:\n",
        "            result = known_face_list[min_distance_index]['name']\n",
        "        else:\n",
        "            result = 'unknown'\n",
        "\n",
        "        distance_with_name_list = [(face_data['name'], round(distance, 4)) for face_data, distance in zip(known_face_list, face_distance_list)]\n",
        "        print(f'辨識檔案: {fn}, 辨識結果: {result}, 特徵距離: {distance_with_name_list}, 相差: {round(abs(distance_with_name_list[0][1] - distance_with_name_list[1][1]), 4)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6a50592-5bfc-4722-a77a-908d804c34e6",
      "metadata": {
        "id": "c6a50592-5bfc-4722-a77a-908d804c34e6"
      },
      "source": [
        "### 使用 5 個特徵點"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a42c865d-a0c9-41b9-a007-4d6915589834",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a42c865d-a0c9-41b9-a007-4d6915589834",
        "outputId": "618a41c6-0f87-4184-c8b8-ec011f99711d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "辨識檔案: lee-t1.jpg, 辨識結果: Lee, 特徵距離: [('Lee', 0.4014), ('Pan', 0.4467)], 相差: 0.0453\n",
            "辨識檔案: lee-t2.jpg, 辨識結果: Lee, 特徵距離: [('Lee', 0.3171), ('Pan', 0.533)], 相差: 0.2159\n",
            "辨識檔案: pan-t1.jpg, 辨識結果: Pan, 特徵距離: [('Lee', 0.4501), ('Pan', 0.3395)], 相差: 0.1106\n",
            "辨識檔案: pan-t2.jpg, 辨識結果: Lee, 特徵距離: [('Lee', 0.3822), ('Pan', 0.3957)], 相差: 0.0135\n"
          ]
        }
      ],
      "source": [
        "known_face_list = [\n",
        "    {\n",
        "        'name': 'Lee',\n",
        "        'filename': 'lee.jpg',\n",
        "        'encode': None,\n",
        "    },\n",
        "    {\n",
        "        'name': 'Pan',\n",
        "        'filename': 'pan.jpg',\n",
        "        'encode': None,\n",
        "    },\n",
        "]\n",
        "\n",
        "test_fn_list = ['lee-t1.jpg', 'lee-t2.jpg', 'pan-t1.jpg', 'pan-t2.jpg']\n",
        "\n",
        "# load image data by large model of face landmarks\n",
        "for data in known_face_list:\n",
        "    img = cv2.imread(data['filename'])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    data['encode'] = face_recognition.face_encodings(img, model='small')[0]  # use small model of face landmarks\n",
        "\n",
        "known_face_encodes = [data['encode'] for data in known_face_list]\n",
        "\n",
        "# face recognition\n",
        "for fn in test_fn_list:\n",
        "    img = cv2.imread(fn)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    cur_face_locs = face_recognition.face_locations(img)\n",
        "    cur_face_encodes = face_recognition.face_encodings(img, cur_face_locs, model='small')  # use small model of face landmarks\n",
        "\n",
        "    for cur_face_encode in cur_face_encodes:\n",
        "        face_distance_list = face_recognition.face_distance(known_face_encodes, cur_face_encode)\n",
        "\n",
        "        min_distance_index = np.argmin(face_distance_list)\n",
        "        if face_distance_list[min_distance_index] < tolerance:\n",
        "            result = known_face_list[min_distance_index]['name']\n",
        "        else:\n",
        "            result = 'unknown'\n",
        "\n",
        "        distance_with_name_list = [(face_data['name'], round(distance, 4)) for face_data, distance in zip(known_face_list, face_distance_list)]\n",
        "        print(f'辨識檔案: {fn}, 辨識結果: {result}, 特徵距離: {distance_with_name_list}, 相差: {round(abs(distance_with_name_list[0][1] - distance_with_name_list[1][1]), 4)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "33f7aa18-3ed6-4419-af41-dc3b42c5635f",
      "metadata": {
        "id": "33f7aa18-3ed6-4419-af41-dc3b42c5635f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}