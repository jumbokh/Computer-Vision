{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIZvpaw0pw2F"
      },
      "source": [
        "# 主題 05-1. 用不同方式使用 Sequential 及學習建立第一個轉移學習模型\n",
        "\n",
        "【註】因 TensorFlow 2 已做了一些改變, 例如完全整合了 Keras。到 2021 年的今天, 有一些細節也做了調整。因此我們依新的規範修改了程式。最大的不同是, 以後大家直接安裝 tensorflow 即可, 不用再另外裝 keras。\n",
        "\n",
        "讓我們回顧一下生命中第一個做出來的神經網路..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G8g0Grvpw2M"
      },
      "source": [
        "## 1. 初始準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYqpft6Tpw2N"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAKyDgsppw2O"
      },
      "outputs": [],
      "source": [
        "# tf.Keras functions\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# tf.Keras dataset\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# tf.Keras utilis function\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQHcLt1Opw2P"
      },
      "source": [
        "## 2. 讀入 MNIST 數據庫"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nrkm66spw2P"
      },
      "source": [
        "### 2.1 由 Keras 讀入 MNIST\n",
        "Keras 很貼心的幫我們準備好 MNIST 數據庫, 我們可以這樣讀進來 (第一周課程中已經讀過)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBlRplPdpw2Q"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1cjoXLxpw2Q"
      },
      "source": [
        "資料的長相"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1vpM_iJpw2R",
        "outputId": "e79452b8-13c6-4ba6-f05b-875ac1e23f88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "總共有 60000 訓練資料，每筆資料的尺寸為 28 x 28\n",
            "總共有 10000 測試資料，每筆資料的尺寸為 28 x 28\n"
          ]
        }
      ],
      "source": [
        "print(\"總共有 %d 訓練資料，每筆資料的尺寸為 %d x %d\" %x_train.shape)\n",
        "print(\"總共有 %d 測試資料，每筆資料的尺寸為 %d x %d\" %x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTWwcoCWpw2S"
      },
      "source": [
        "### 2.3 輸入格式整理\n",
        "\n",
        "我們現在要用標準神經網路學學手寫辨識。原來的每筆數據是個 28x28 的矩陣 (array), 但標準神經網路只吃「平平的」, 也就是每次要 28x28=784 長的向量。因此我們要用 `reshape` 調校一下。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlPsuuL7pw2T"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(60000, 784)/255\n",
        "x_test = x_test.reshape(10000, 784)/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDxNm789pw2T"
      },
      "source": [
        "為了後面需要，我們把訓練/測試資料中的數字 0, 1 資料，複製一份出來"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_doLyVIpw2T"
      },
      "outputs": [],
      "source": [
        "x_train_01 = x_train[y_train <= 1]\n",
        "x_test_01 = x_test[y_test <= 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt0ZGOPipw2T"
      },
      "source": [
        "並將 label 轉換成 one-hot encoding 的形式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rb2K3uKgpw2T"
      },
      "outputs": [],
      "source": [
        "y_train_10 = to_categorical(y_train, 10)\n",
        "y_test_10 = to_categorical(y_test, 10)\n",
        "\n",
        "y_train_01 = y_train[y_train <= 1]\n",
        "y_train_01 = to_categorical(y_train_01, 2)\n",
        "\n",
        "y_test_01 = y_test[y_test <= 1]\n",
        "y_test_01 = to_categorical(y_test_01, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Isx--aY3pw2U"
      },
      "source": [
        "養成良好的習慣，適時的確認資料的大小以確保資料的一致性"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBcNSfTHpw2U",
        "outputId": "0bd37873-26a2-4ba9-cd48-054c43fb56c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((12665, 784), (2115, 784))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train_01.shape, x_test_01.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGKnN4Ljpw2U",
        "outputId": "dbde4104-0e16-4728-f1dd-f8a427272142"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((12665, 2), (2115, 2))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_01.shape, y_test_01.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_hI4nqKpw2V"
      },
      "source": [
        "## 3. 回顧一下 Sequential API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf8xcFXapw2V"
      },
      "source": [
        "在一開始的時候，我們以下列的方式建立了一個具有下列設定\n",
        "\n",
        "* 使用 <span style=\"color:red;\">2</span> 個 hidden layers\n",
        "* 每個 hidden layer 用 <span style=\"color:red;\">500</span> 個神經元\n",
        "* Activation Function 唯一指名 <span style=\"color:red;\">sigmoid</span>\n",
        "\n",
        "的神經網路，建立指令是透過建立 `Sequential()` 和 `.add` 的方式逐層建立，如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeNe8KZEpw2V",
        "outputId": "fec36933-7ec8-46cb-e4ab-82bd6d55d91c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 500)               392500    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5010      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 648,010\n",
            "Trainable params: 648,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Construct a sandbox to put layers inside\n",
        "model = Sequential()\n",
        "\n",
        "# Put fully-connected layers (Dense) inside\n",
        "model.add(Dense(500, input_dim=784))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(500))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg8f0un2pw2V"
      },
      "source": [
        "### 3.1 觀察 model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "friwMEwwpw2V"
      },
      "source": [
        "觀察 `model.layers`，可以發現 `model` 其實就是一堆神經網路層疊起來。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ybAB--A0pw2W",
        "outputId": "7974f581-4b16-4129-d5b6-4d8fef199151"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.core.Dense at 0x7ff05c480c10>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7ff05c4a6370>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7ff0591bafd0>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7ff0591bad60>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7ff059174400>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7ff0591757f0>]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2Jkb79Wpw2W"
      },
      "source": [
        "換言之，剛剛每一個 `.add` 其實在做的事情就是：\n",
        "\n",
        "`model.add(Dense(500, input_dim=784))` 是將 `<keras.layers.core.Activation at 0xe558ef0>` 加進 model.layers\n",
        "\n",
        "`model.add(Activation('sigmoid'))` 是將 `<keras.layers.core.Dense at 0xe58a278>` 加入 model.layers\n",
        "\n",
        "`model.add(Dense(500))` 是將 `<keras.layers.core.Dense at 0xe58a278>` 加入 model.layers\n",
        "\n",
        "`model.add(Activation('sigmoid'))` 是將 `<keras.layers.core.Activation at 0xe558d68>` 加入 model.layers\n",
        "\n",
        "`model.add(Dense(10))` 是將 `<keras.layers.core.Activation at 0xe558d68>` 加入 model.layers\n",
        "\n",
        "`model.add(Activation('softmax'))` 是將 `<keras.layers.core.Activation at 0xe58a898>` 加入 model.layers\n",
        "\n",
        "* 這邊的 at 0xe558ef0 代表的是記憶體位置，每次執行都會不一樣，所以和上面結果不同是正常的。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0YCxQqXpw2W"
      },
      "source": [
        "### 3.2 以 list 的形式使用 Sequential API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7wd32zJpw2W"
      },
      "source": [
        "換言之，神經網路其實就是將隱藏層逐層堆疊在一起的 list，因此，我們也可以 list 的形式來建立相同的神經網路。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNUCkd6Ypw2W"
      },
      "source": [
        "首先，我們將兩個隱藏層及其 Activation Function 分別寫在 list 中，如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_de2UCapw2W"
      },
      "outputs": [],
      "source": [
        "first_layer = [Dense(500, input_dim=784),\n",
        "               Activation('sigmoid')]\n",
        "\n",
        "second_layer = [Dense(500),\n",
        "                Activation('sigmoid')]\n",
        "\n",
        "output_layer = [Dense(10),\n",
        "                Activation('softmax')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RhMuKcqpw2W"
      },
      "source": [
        "從基本的 Python 資料結構中，我們知道 list 可以用 `+` 來進行合併，所以我們先來看看這三個 list 合併後的樣子。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSIKe_iXpw2X",
        "outputId": "bbc39be0-f5cd-4ec5-8205-8f8fd891f9eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.core.Dense at 0x7ff05910a790>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7ff05910ab20>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7ff05910a700>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7ff05910afd0>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7ff05910ab80>,\n",
              " <tensorflow.python.keras.layers.core.Activation at 0x7ff05c480910>]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_layer + second_layer + output_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GxpVykvpw2X"
      },
      "source": [
        "合併起來的 list 看起來就像是**某個** `model.layers` 一樣，我們接著要做的，就讓這個 list **真的**變成某個神經網路的 `.layers`\n",
        "\n",
        "很簡單，只要將寫成 list 的隱藏層 `+` 起來送進 `Sequential` 中即可。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cLnmsh9pw2X"
      },
      "outputs": [],
      "source": [
        "model = Sequential(first_layer + second_layer + output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "63X4uRlIpw2X",
        "outputId": "2560ad51-cc8f-40a0-8274-1238f97be4b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 500)               392500    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                5010      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 648,010\n",
            "Trainable params: 648,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRkFPPF3pw2X"
      },
      "source": [
        "Q: 用 `.add` 和用 list 寫法建立的神經網路之差異？\n",
        "\n",
        "A: 沒有任何差別，前者可以很直覺的建立神經網路，但後者則為使用轉移學習(transfer Learning)的手法之一，前者雖也可做，但較麻煩。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFnS_Jyppw2Y"
      },
      "source": [
        "## 4. 情境題:假設我們手上有一個好棒棒的 MNIST 手寫辨識模型，但我今天想建立可以辨識 0 或 1 的模型，除了最後一層，想沿用前兩層的網路設定及結構，我該怎麼做？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U5Yq1sUpw2Y"
      },
      "source": [
        "首先，我們準備一個上面一樣的神經網路手寫辨識模型，除了最後一層之外都被包在一起。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1Tfpu2tpw2Y",
        "outputId": "c37fd774-f0f5-426a-c059-d10899c661c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 500)               392500    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                5010      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 648,010\n",
            "Trainable params: 648,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "all_except_last = [Dense(500, input_dim=784),\n",
        "                   Activation('sigmoid'),\n",
        "                   Dense(500),\n",
        "                   Activation('sigmoid')]\n",
        "\n",
        "output_layer = [Dense(10),\n",
        "                Activation('softmax')]\n",
        "\n",
        "model_0_to_9 = Sequential(all_except_last + output_layer)\n",
        "model_0_to_9.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T5E1gKSpw2Y"
      },
      "source": [
        "建立完成後，我們讀取第一周已經訓練好的神經網路權重。\n",
        "\n",
        "若同學們沒有 `handwriting_model_weights.h5` 這份模型的權重檔，請至 https://github.com/yenlung/Deep-Learning-MOOC 下載"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyclC03Kpw2d"
      },
      "outputs": [],
      "source": [
        "model_0_to_9.load_weights('handwriting_model_weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHE-s98_pw2d"
      },
      "source": [
        "由於我們沒有要真的使用這個手寫辨識模型，所以不需要 compile、fit、predict 或 evaluate。\n",
        "\n",
        "接著，我們定義新的 output layer。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3NS38xjpw2d",
        "outputId": "e7d1051d-be69-42e7-ed4e-7e570e8caf95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 500)               392500    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2)                 1002      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 644,002\n",
            "Trainable params: 644,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "new_output_layer = [Dense(2),\n",
        "                    Activation('softmax')]\n",
        "\n",
        "model_0_to_1 = Sequential(all_except_last + new_output_layer)\n",
        "model_0_to_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcB2h3z_pw2d"
      },
      "source": [
        "要注意的是，如果我們僅沿用而不訓練到前兩層，我們可以透過下面的方式將借過來的神經網路 **冷凍** 起來"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcmHc0Uxpw2e"
      },
      "outputs": [],
      "source": [
        "for layer in all_except_last:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ1YMXjxpw2e"
      },
      "source": [
        "**冷凍**後的神經網路的 summary 會有些變化，你有發現嗎? ：)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmcQsInspw2e",
        "outputId": "4a83ce62-285f-4266-8dfd-622060c1b87a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 500)               392500    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2)                 1002      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 644,002\n",
            "Trainable params: 1,002\n",
            "Non-trainable params: 643,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_0_to_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz4U9yUmpw2e"
      },
      "source": [
        "接著，我們來訓練這個(有一部分架構及權重跟別人借用的) 0 或 1 手寫辨識模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YyCYCfGpw2e"
      },
      "outputs": [],
      "source": [
        "model_0_to_1.compile(loss='mse', optimizer=SGD(lr=0.1), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8ln-qaypw2f"
      },
      "source": [
        "## 5. 訓練你的第一個透過轉移學習學到的神經網路\n",
        "\n",
        "恭喜! 我們完成了第一個 transfer leraning 的神經網路。這裡我們還有兩件事要決定:\n",
        "\n",
        "* 一次要訓練幾筆資料 (`batch_size`), 我們就 100 筆調一次參數好了\n",
        "* 這 ~~6 萬筆資料~~ 12665 筆資料一共要訓練幾次 (`epochs`), 我們訓練個 5 次試試 (因為只剩 0 或 1的資料了，訓練太多容易 over-fitting)\n",
        "\n",
        "於是最精彩的就來了。你要有比第一周快上100倍的心理準備... (這是因為訓練資料只剩下 1/5，且**可訓練**權重數量從 64萬變成 1千)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oegFi22_pw2f",
        "outputId": "3b3e553d-6fee-4cfe-dd3c-8aec763dace7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((12665, 784), (12665, 2))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train_01.shape, y_train_01.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "wU94JrSppw2f",
        "outputId": "bfbea5a4-86b9-4217-a7f6-a12b06fd2315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "127/127 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.5907\n",
            "Epoch 2/5\n",
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0517 - accuracy: 0.9733\n",
            "Epoch 3/5\n",
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9949\n",
            "Epoch 4/5\n",
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9951\n",
            "Epoch 5/5\n",
            "127/127 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 0.9960\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff0590cc520>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_0_to_1.fit(x_train_01, y_train_01, batch_size=100, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrOas3ykpw2g",
        "outputId": "9fab19c6-ec5a-4747-99ac-f7f22ddd3abf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "67/67 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 0.9976\n"
          ]
        }
      ],
      "source": [
        "score = model_0_to_1.evaluate(x_test_01, y_test_01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6CmCtkLpw2g",
        "outputId": "7221450e-c797-4d63-8046-9f0d2a7e99ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "測試資料的 loss: 0.010476105846464634\n",
            "測試資料正確率: 0.9976359605789185\n"
          ]
        }
      ],
      "source": [
        "print('測試資料的 loss:', score[0])\n",
        "print('測試資料正確率:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW7VwmP_pw2g"
      },
      "source": [
        "## 6. 恭喜你完成了第一個透過轉移學習得到的神經網路模型！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BviQh_hlpw2g"
      },
      "source": [
        "雖然這個模型看起來很隨便，但轉移學習的模型**差不多**都是這樣建立的，實際上， Keras 亦提供許多被證實有良好表現且訓練好 (pre-trained) 的模型，如:\n",
        "\n",
        "* Xception\n",
        "* VGG16\n",
        "* VGG19\n",
        "* ResNet50\n",
        "* InceptionV3\n",
        "* InceptionResNetV2\n",
        "* MobileNet\n",
        "* DenseNet\n",
        "* NASNet\n",
        "\n",
        "詳細的使用方式可參考 Keras Documentation: https://keras.io/applications/\n",
        "\n",
        "但使用這些模型進行轉移學習，**可能**需要其他更彈性的神經網路寫法，更多神經網路的建構技巧，待下次課程繼續。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tf2py38]",
      "language": "python",
      "name": "conda-env-tf2py38-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}