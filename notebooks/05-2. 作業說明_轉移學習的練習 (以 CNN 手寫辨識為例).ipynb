{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdD0ballpX88"
      },
      "source": [
        "# 主題 05-2. 轉移學習的練習\n",
        "\n",
        "【註】因 TensorFlow 2 已做了一些改變, 例如完全整合了 Keras。到 2021 年的今天, 有一些細節也做了調整。因此我們依新的規範修改了程式。最大的不同是, 以後大家直接安裝 tensorflow 即可, 不用再另外裝 keras。\n",
        "\n",
        "讓我們回顧一下生命中第一個做出來的 CNN 圖形辨識模型..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQSqMSDQpX9B"
      },
      "source": [
        "## 1. 初始準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_rJ_LlTpX9C"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw5F4F8qpX9D"
      },
      "outputs": [],
      "source": [
        "# tf.Keras functions\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# tf.Keras dataset\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Keras utilis function\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65vTKKUtpX9E"
      },
      "source": [
        "## 2. 讀入 MNIST 數據庫\n",
        "\n",
        "MNIST 是有一堆 0-9 的手寫數字圖庫。有 6 萬筆訓練資料, 1 萬筆測試資料。它是 \"Modified\" 版的 NIST 數據庫, 原來的版本有更多資料。這個 Modified 的版本是由 LeCun, Cortes, 及 Burges 等人做的。可以參考這個數據庫的[原始網頁](http://yann.lecun.com/exdb/mnist/)。\n",
        "\n",
        "MNIST 可以說是 Deep Learning 最有名的範例, 它被 Deep Learning 大師 Hinton 稱為「機器學習的果蠅」。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDCNQ_yUpX9E"
      },
      "source": [
        "### 2.1 由 tf.Keras 讀入 MNIST\n",
        "tf.Keras 很貼心的幫我們準備好 MNIST 數據庫, 我們可以這樣讀進來 (第一周課程中已經讀過)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZfVeyPTpX9F"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f9mPSvFpX9F"
      },
      "source": [
        "我們可以看看資料的長相"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG-WD8LqpX9G",
        "outputId": "b463a5b9-fc5b-4cf9-8a0d-3f8e6b0b1a56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 60000 training data with size 28 x 28\n",
            "There are 10000 testing  data with size 28 x 28\n"
          ]
        }
      ],
      "source": [
        "print(\"There are %d training data with size %d x %d\" %x_train.shape)\n",
        "print(\"There are %d testing  data with size %d x %d\" %x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTp6JwBapX9H"
      },
      "source": [
        "### 2.3 輸入格式整理\n",
        "\n",
        "我們現在要用 CNN 學手寫辨識。因為 CNN 模型的資料需要多一個 channel (通道數)，因此我們要用 `reshape` 調校一下。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vpWWzPDpX9H"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(60000, 28, 28, 1)/255\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xDc8zoOpX9I"
      },
      "source": [
        "為了後面需要，我們先將數字 0 和 1 的資料分別抓出來"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TfFiritpX9I"
      },
      "outputs": [],
      "source": [
        "x_train_01 = x_train[y_train <= 1]\n",
        "x_test_01 = x_test[y_test <= 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x68eZXc5pX9I"
      },
      "source": [
        "並將 label 轉換成 one-hot encoding 的形式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5zOiVoBpX9I"
      },
      "outputs": [],
      "source": [
        "y_train_10 = to_categorical(y_train, 10)\n",
        "y_test_10 = to_categorical(y_test, 10)\n",
        "\n",
        "y_train_01 = y_train[y_train <= 1]\n",
        "y_train_01 = to_categorical(y_train_01, 2)\n",
        "\n",
        "y_test_01 = y_test[y_test <= 1]\n",
        "y_test_01 = to_categorical(y_test_01, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T51j2bZjpX9I"
      },
      "source": [
        "養成良好的習慣，適時的確認資料的大小以確保資料的一致性"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOWzDmpVpX9J",
        "outputId": "5d2de57a-8d5c-4af6-a539-e4dfae17180d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((12665, 28, 28, 1), (2115, 28, 28, 1))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train_01.shape, x_test_01.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKdSADHdpX9J",
        "outputId": "241794d0-2d8e-4270-ced9-81299963d87e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((12665, 2), (2115, 2))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_01.shape, y_test_01.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5gIpbWtpX9J"
      },
      "source": [
        "# 3. 回顧 CNN 圖形辨識模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "265NMIaSpX9J"
      },
      "source": [
        "經典的 CNN 圖形辨識模型 LeNet-5 是一個由兩層卷積層加三層全連接層所建立的神經網路，而在第二單元時，我們建立的 CNN 模型設定如下：\n",
        "\n",
        "* 起始為 <span style=\"color:red;\">3</span> 個 convolutional block\n",
        " + 每個 convolutional block 為 <span style=\"color:red;\">1</span> 個 2D Convolution + ReLU + <span style=\"color:red;\">1</span> 個 2D MaxPooling\n",
        " + 2D Convolution 的數量為 32, 64, 128\n",
        " + 每個 2D Convolution 的 `kernal_size` 為 3 或 (3, 3)，`padding` 使用 `same`\n",
        " + 每個 2D MaxPooling 的 `pool_size` 為 2 或 (2, 2)，`padding` 使用 `same`\n",
        "\n",
        "* 將輸出結果 `Flatten` 後，接著兩層全連接層，神經元個數分別為 200 和 10 (<span style=\"color:red;\">數字的類別總數)</span>\n",
        "\n",
        "我們當時建立的，是一個具有三層卷積層加兩層全連接的神經網路，其實可以看成是 LeNet-5 的一種變形。\n",
        "\n",
        "根據本單元的內容，我們可以使用下列方式使用 Sequential 重新建構第二單元的 CNN 模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1MiZAXvpX9K",
        "outputId": "950f0262-0aa0-4752-f8e0-b11cac85c153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               230600    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2010      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 325,282\n",
            "Trainable params: 325,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# We put 3 conv. blocks together, called conv_layer.\n",
        "conv_layer = [Conv2D(32, (3, 3), padding='same', input_shape=(28,28,1)),\n",
        "              Activation('relu'),\n",
        "              MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "              Conv2D(64, (3, 3), padding='same'),\n",
        "              Activation('relu'),\n",
        "              MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "              Conv2D(128, (3, 3), padding='same'),\n",
        "              Activation('relu'),\n",
        "              MaxPooling2D(pool_size=(2, 2))]\n",
        "\n",
        "# We put Flatten, and 2 fully-connectd layers together, called fc_layer.\n",
        "fc_layer = [Flatten(),\n",
        "            Dense(200),\n",
        "            Activation('relu'),\n",
        "            Dense(10),\n",
        "            Activation('softmax')]\n",
        "\n",
        "model = Sequential(conv_layer + fc_layer)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW402Sg7pX9K"
      },
      "outputs": [],
      "source": [
        "model.load_weights('handwriting_weights_cnn.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvUL5pYnpX9K"
      },
      "source": [
        "# 4. 保留前三層 convolutional layer 並進行轉移學習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C8oE6BzpX9K"
      },
      "source": [
        "在此，我們一樣將 MNIST 資料集將僅有 0, 1的部分取出來，我們希望透過轉移學習建立一個類似 LeNet-5 的 0, 1 圖形辨識模型。\n",
        "\n",
        "請將下列三個 **None** 的部分進行修改，以透過轉移學習建立新的模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsX0Z2BVpX9K"
      },
      "outputs": [],
      "source": [
        "new_fc_layer = [Flatten(),\n",
        "                ### Design your own fully connected structures ###\n",
        "                Dense(None),\n",
        "                Activation(None),\n",
        "                Dense(None),       ## Hint: how many classes in new dataset?\n",
        "                ### Remember put correct number of unit for output ###\n",
        "                Activation('softmax')]\n",
        "\n",
        "model_0_to_1 = Sequential(conv_layer + None)\n",
        "model_0_to_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkN8P86spX9L"
      },
      "source": [
        "請將下列的 **None** 進行修改，以將借過來的神經網路 **冷凍** 起來："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdroBMOIpX9L"
      },
      "outputs": [],
      "source": [
        "for layer in None:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W08uB--spX9L"
      },
      "source": [
        "**冷凍**後的神經網路的 summary 會有些變化，你有發現嗎? ：)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV1oy7cupX9L"
      },
      "outputs": [],
      "source": [
        "model_0_to_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHjim7CDpX9L"
      },
      "source": [
        "接著，我們來訓練這個(有一部分架構及權重跟別人借用的) 0, 1 手寫辨識模型吧！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHBUFwKkpX9L"
      },
      "outputs": [],
      "source": [
        "model_0_to_1.compile(loss='mse', optimizer=SGD(learning_rate=0.1), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFZa-HHppX9L"
      },
      "source": [
        "## 5. 訓練"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRb5t1fopX9M"
      },
      "outputs": [],
      "source": [
        "model_0_to_1.fit(x_train_01, y_train_01, batch_size=100, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAPkuBpJpX9M"
      },
      "outputs": [],
      "source": [
        "score = model_0_to_1.evaluate(x_test_01, y_test_01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRMb58HjpX9M"
      },
      "outputs": [],
      "source": [
        "print('測試資料的 loss:', score[0])\n",
        "print('測試資料正確率:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "905ka1bHpX9M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPFJZ3nypX9M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Tbw2UmWpX9M"
      },
      "source": [
        "## 6. 恭喜你完成了第二個透過轉移學習得到的神經網路模型！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP6IBcOUpX9N"
      },
      "source": [
        "不難發現，如果模型大部分的權重已經訓練好並冷凍起來，則轉移學習可以大幅減少訓練時間且訓練會更快收斂，那麼，是否還有其他重要的模型建構技巧呢？\n",
        "\n",
        "這個問題我們留待下個單元解答囉~ : )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxrkQM0SpX9R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tf2py38]",
      "language": "python",
      "name": "conda-env-tf2py38-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}